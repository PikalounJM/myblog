---
title: Text Mining "Anti-discrimination law"
description: "Text mining, Crawling, One-hot encoding, Wordcloud"
category: projects
dateString: Oct 2022 - Dec 2022 
cover:
  image: "img/law.PNG"
  alt:
  caption:
  relative: 
showtoc: true
draft: false
weight: 204
---

### Coding
  The complete code can be found on ğŸ”— [GitHub](https://github.com/PikalounJM/Text-Mining/blob/main/Non-discrimination.ipynb)

### Backgroud
- As part of an M.S. assignment project, an analysis of public awareness through the identification of trends in support of and opposition to the 'Anti-Discrimination law' using web crawling.

### Dataset & Tool
- Naver news and blog & **Python**

&nbsp;

### âœï¸ Code Example

**1) í˜•íƒœì†Œ ë¶„ì„(Morphology Analysis)**

```python
import konlpy
from konlpy.tag import Okt
from konlpy.tag import Hannanum, Kkma, Komoran, Mecab

new_list = "".join(list)

#í˜•íƒœì†Œ ë¶„ì„

twt = Okt()
sentence_tag = []
for sentence in list:
    morph = twt.pos(sentence)
    sentence_tag.append(morph)
    print(morph)
    print('-' * 30)

update = twt.morphs(new_list)

from collections import Counter
update1 = Counter(update)
print(update1)

#ëª…ì‚¬ ë¹ˆë„ ë¶„ì„
noun = twt.nouns(new_list)

from collections import Counter
noun1 = Counter(noun)
print(noun1)

#ë°ì´í„° ìˆœìœ„: 1ìœ„)ì°¨ë³„ê¸ˆì§€ë²•, 2ìœ„) ì°¨ë³„, 3ìœ„) í•œêµ­, 4ìœ„) ì„±ì†Œìˆ˜ì, 5ìœ„) ì„±ì ì§€í–¥
```
&nbsp;

**2) í¬ë¡¤ë§(Crawling)**

```python
#ë„¤ì´ë²„ì— 'ì°¨ë³„ê¸ˆì§€ë²•' ê²€ìƒ‰ í›„, ë‰´ìŠ¤ ì œëª© ë° URL í¬ë¡¤ë§
import requests
from pandas import DataFrame
from bs4 import BeautifulSoup
import re
from datetime import datetime
import os

date = str(datetime.now())
date = date[:date.rfind(':')].replace(' ', '_')
date = date.replace(':','ì‹œ') + 'ë¶„'

query = 'ì°¨ë³„ê¸ˆì§€ë²•'
news_num = 150
query = query.replace(' ', '+')


news_url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={}'

req = requests.get(news_url.format(query))
soup = BeautifulSoup(req.text, 'html.parser')


news_dict = {}
idx = 0
cur_page = 1

while idx < news_num:

    table = soup.find('ul',{'class' : 'list_news'})
    li_list = table.find_all('li', {'id': re.compile('sp_nws.*')})
    area_list = [li.find('div', {'class' : 'news_area'}) for li in li_list]
    a_list = [area.find('a', {'class' : 'news_tit'}) for area in area_list]

    for n in a_list[:min(len(a_list), news_num-idx)]:
        news_dict[idx] = {'title' : n.get('title'),
                          'url' : n.get('href')}
        idx += 1

    cur_page += 1

    pages = soup.find('div', {'class' : 'sc_page_inner'})
    next_page_url = [p for p in pages.find_all('a') if p.text == str(cur_page)][0].get('href')

    req = requests.get('https://search.naver.com/search.naver' + next_page_url)
    soup = BeautifulSoup(req.text, 'html.parser')

news_df = DataFrame(news_dict).T
```
&nbsp;

**3) ì›-í•« ì¸ì½”ë”©(One-hot encoding)**

```python
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.cluster import KMeans
from pyclustering.cluster import kmedoids
import numpy as np

vec = CountVectorizer()
X = vec.fit_transform(document)

df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())
```
![One-hot](/img/onehot.PNG)

&nbsp;

**4) ì›Œë“œí´ë¼ìš°ë“œ(Wordcloud)**

```python
from wordcloud import WordCloud #í† ë¼ ì´ë¯¸ì§€ë¡œ ì›Œë“œí´ë¼ìš°ë“œ ì‹œê°í™”í•˜ê¸°
from collections import Counter
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

font_path = 'HMFMMUEX.TTC'

animal_mask = np.array(Image.open("animal.png"))

wordcloud = WordCloud(
    font_path = font_path,
    width = 800,
    height = 800,
    background_color="white",
    mask = animal_mask)

count = Counter(word_list)
wordcloud = wordcloud.generate_from_frequencies(count)
plt.figure(figsize=(10, 10))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()
```
&nbsp;

**5) í† í”½ ëª¨ë¸ë§(Topic modeling)**

```python
from gensim.models import CoherenceModel

print('\nPerplexity: ', ldamodel.log_perplexity(corpus)) #ë³µì¡ë„ ê³„ì‚°í•˜ê³  ê·¸ ì•ˆì— ë‹¨ì–´ë“¤ë¡œ êµ¬ì„±ëœ topicì•ˆì—ì„œ ì‘ì§‘ì„±ì´ ì–´ëŠì •ë„ì¸ì§€ scoring
coherence_model_lda = CoherenceModel(model=ldamodel, texts=texts, dictionary=dictionary,topn=10)
coherence_lda = coherence_model_lda.get_coherence()
print('\nCoherence Score: ', coherence_lda) #ì‘ì§‘ë„, ì‘ì§‘ë„ê°€ ë‚®ì„ê²½ìš°ì—ëŠ” ì“°ì§€ ì•ŠëŠ”ê²ƒì´ ì¢‹ë‹¤.
```

Perplexity:  -7.837716129815166

Coherence Score:  0.6466521187737081

**âœï¸ Graph**

```python
import matplotlib.pyplot as plt
perplexity_values = []
for i in range(2,10):
    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=i, id2word = dictionary)
    perplexity_values.append(ldamodel.log_perplexity(corpus))

x = range(2,10)
plt.plot(x, perplexity_values)
plt.xlabel("Number of topics")
plt.ylabel("Perplexity score")
plt.show() #5ê°œ ì´ìƒì´ ë„˜ì–´ê°€ë©´ ë³µì¡ë„ê°€ ë–¨ì–´ì§

coherence_values = []
for i in range(2,10):
    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=i, id2word = dictionary)
    coherence_model_lda = CoherenceModel(model=ldamodel, texts=texts, dictionary=dictionary,topn=10)
    coherence_lda = coherence_model_lda.get_coherence()
    coherence_values.append(coherence_lda)

x = range(2,10)
plt.plot(x, coherence_values)
plt.xlabel("Number of topics")
plt.ylabel("coherence score")
plt.show() #5ê°œë¥¼ ë½‘ì•˜ì„ë•Œê°€ ì‘ì§‘ë„ ìˆ«ìê°€ ê°€ì¥ ë†’ìŒ. ì‘ì§‘ë ¥ì´ ê°€ì¥ ë†’ì„ ë•Œì™€ Perplexityê°€ ë†’ì§€ ì•Šì„ë•Œê°€ ê°€ì¥ ì ì ˆí•¨
```

